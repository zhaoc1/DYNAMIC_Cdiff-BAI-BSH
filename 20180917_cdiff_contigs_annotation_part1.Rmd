---
title: "C. difficile contigs annotation (part 1)"
author: "Chunyu Zhao"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    highlight: tango
    number_sections: yes
    toc: yes
    toc_depth: 3
geometry: "left=1cm,right=1cm,top=2cm,bottom=2cm"
editor_options: 
  chunk_output_type: console
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(
  tidy=FALSE,
  cache=FALSE,
  echo=FALSE,
  message = FALSE,
  warning = FALSE,
  dpi=100,
  fig.align = "center",
  fig.width = 8,
  cache.lazy = FALSE,
  dev=c("png", "pdf"),
  warning=FALSE)
```

```{r}
library(tidyverse)
library(readr)
library(reshape2)
library(ggbeeswarm)
library(scales)
library(stringr)
library(RColorBrewer)
library(viridis)
library(pander)
library(magrittr)
library(forcats)
library(ggbeeswarm)
library(ggsci)
library(scales)

library(gridExtra)
library(grid)

library(pheatmap)

source("new_helper.R")
```

# Origin of Species

## ReadME

- 20180918: this comes the blast database need to be non-redundant ....

- 20180917: move the cdiff contigs annotation and kraken part from `20180810_bsh_report.Rmd` here.

- 20181005: blastn re-annotation. I suspect it's the contigs assembly problem, and I didn't update the Clostridium_difficile results. Also, later on, I make my mind it's better to get the coverage of the contigs (longer than 500 bps).

- 20181005: add on the **qPCR** results for C diff toxin genes from Lisa.

- 20181017: since the refseq top 100 records is too big, I splitted the contigs taxonomic assignment into two steps

- 20181122: the challenge is how to define the **best** hit

- 20181218: I cleaned up the old R code and RDS data

```{r misc functions}
grp.filter <- function(pident.dict, query){
    pident.dict %>% filter(qseqid %in% query) %>% .$qident.max %>% as.numeric()
}

taxa_headers <- c("superkingdom", "phylum", "class", "order", "family", "genus", "species")

first_word <- function (x) sapply(strsplit(x, " "), `[`, 1)

find_common_ancestor_nomore <- function(test_taxonomy) {
  temp <- as.character(test_taxonomy[[1,names(tail(which(lapply(apply(test_taxonomy, 2, unique), length) == 1), n=1))]])
  if (is.null(temp)) {
    temp <- "NA"
  }
  temp
}

## same bit score, different species <- it's really not fair to use any species. instead let's find the so called common ancestor
find_common_ancestor <- function(test_taxonomy) {
  
  taxa_headers <- c("superkingdom", "phylum", "class", "order", "family", "genus", "species")
  
  id.lca <- tail(which(lapply(apply(test_taxonomy, 2, unique), length) == 1), n=1)
  
  ## initialize
  lca <- data.frame("NA", "p__NA", "c__NA", "o__NA", "f__NA", "g__NA", "s__NA", stringsAsFactors = FALSE)
  colnames(lca) <- taxa_headers
  
  ## 
  if (id.lca > 0) {
    lca[1:id.lca] <- test_taxonomy[1, taxa_headers[1:id.lca]]
  }
  as.data.frame(lca)
}

```

## Step 1: raw blastn parsing

- blastn_20181125.rds: read_blastn_refseq(opt = "advanced", date= "20181125"); ugh I accidently deleted this file.
- blastn_20181219.rds: read_blastn_refseq(opt = "advanced", date= "20181219")

```{r step1 read in raw and process, eval=FALSE}
library(foreach)
library(doParallel)

read_blastn_refseq <- function(filepath, opt = "advanced") {
  
  require(tidyverse)
  require(readr)
  require(magrittr)

  sample_id <- sub("*.blastn", "", basename(filepath))
  
  blastn <- readr::read_delim(filepath, delim="\t", col_names = F)
  
  if (nrow(blastn) == 0){
    print(paste("empty blastn search for", sample_id))
    return(data.frame(sample = sample_id, qseqid=NA))
  }
  
  blastn %<>%
    set_colnames(c("qseqid", "sseqid", "pident", "qlen","slen","length", "mismatch", "gapopen", "qstart", "qend", "sstart", "send", "e_value", "bit_score"))
  
  ## file too big, we need to do some filtering
  ## a loose cov cutoff of qcov: 0.25
  blastn %<>%
    mutate(qcov = length / qlen) %>%
    filter(qlen >= 500) %>%
    filter(qcov >= 0.25) %>%
    select(-one_of(c("qstart", "qend", "sstart", "send")))
  
  ## traditionally select the best hit(s)
  ## the higher the bit-score, the better the sequence similarity
  blastn.1 <- blastn %>%
    group_by(qseqid) %>%
    filter(bit_score == max(bit_score)) %>%
    ungroup()
  
  if (opt == "advanced"){
    blastn.2 <- blastn %>%
      ## (wrong) the larger the qcov is, the better; EXCEPT insertion
      ## for insertion, the qcov.abs > 1
      ## (correction) the more close to 1, the better
      ## aka the smaller the qcov.rel is, the better
      mutate(qcov.rel = abs(qcov - 1)) %>% 
      group_by(qseqid) %>%
      filter(qcov.rel == min(qcov.rel)) %>%
      ungroup()
    
    ## only when the top qcov ones also have a close enough descent pident
    pident.dict <- blastn.1 %>%
      group_by(qseqid) %>%
      summarise(qident.max = max(pident)) %>%
      ungroup()
    
    blastn.2 %<>%
      rowwise() %>% 
      mutate(pident.grp = grp.filter(pident.dict, qseqid)) %>%
      mutate(pident.cmp =  pident.grp - pident) %>%
      filter(pident.cmp <= 5)
    
    ## okay now we get our candidates: best qcov and comparable pident with the best bit score
    blastn.2 %<>% select(-one_of("qcov.rel"))
    blastn.1 %<>% mutate(pident.cmp = -1, pident.grp = pident)
  
    blastn <- rbind(blastn.1, blastn.2) %>% unique()
  } else {
    blastn.1 %<>% mutate(pident.cmp = -1, pident.grp = pident)
    blastn <- blastn.1
  }
  
  data.frame(sample = sample_id, blastn)
}


#summary_dir <- "sunbeam_output_20180731/20181004_blastn_bacteria/contigs/"
summary_dir <- "sunbeam_output_20180731/20181218_blastn_bacteria/contigs/"

summary_files <- list.files(summary_dir)
db <- "bacteria"


#setup parallel backend to use many processors
cores=detectCores()
cl <- makeCluster(pmin(cores[1]-5, length(summary_files))) #not to overload your computer
registerDoParallel(cl)

blastn <- foreach(i=1:length(summary_files), .combine=rbind) %dopar% {
  persample <- read_blastn_refseq(file.path(summary_dir, summary_files[i]), opt="advanced")
  persample
}
#stop cluster
stopCluster(cl)

#saveRDS(blastn, file="blastn_20181125.rds")
saveRDS(blastn, file="blastn_20181219.rds")
```

## Step 2: taxonomizr

- blastn_20181125_taxa.rds
- blastn_20181219_taxa.rds

```{r, eval=FALSE}
#blastn <- readRDS("blastn_20181125.rds")
blastn <- readRDS("blastn_20181219.rds")

##### Convert into taxonomy name
library(taxonomizr)
library(data.table)

taxaNodes<-read.nodes('/home/chunyu/biodata/taxonomizr_20170925/nodes.dmp')
taxaNames<-read.names('/home/chunyu/biodata/taxonomizr_20170925/names.dmp')
accessionTaxasql <- "/home/chunyu/biodata/taxonomizr_20170925/accessionTaxa.sql"

blastn %<>%
  dplyr::mutate(taxaID = accessionToTaxa(sseqid, accessionTaxasql)) 
blastn <- cbind(blastn, getTaxonomy(blastn$taxaID,taxaNodes,taxaNames))

# Keep all the results without filtering NA
#saveRDS(blastn, file="blastn_20181125_taxa.rds")
saveRDS(blastn, file="blastn_20181219_taxa.rds")
```

## Step 3: common ancestor

- blastn_20181125_taxa_common.rds
- blastn_20181219_taxa_common.rds

```{r 20181127 after power outbreake, eval=FALSE}
#blastn <- readRDS("blastn_20181125_taxa.rds")
blastn <- readRDS("blastn_20181219_taxa.rds")

blastn %<>% filter(! is.na(taxaID))

## same bit score, different accession number but same species
blastn %<>%
  group_by(sample, qseqid, species) %>%
  filter(row_number() == 1) %>%
  ungroup()

## add some indicators
blastn %<>% 
  mutate(species = paste("s", species, sep="__")) %>%
  mutate(genus = paste("g", genus, sep="__")) %>%
  mutate(family = paste("f", family, sep="__")) %>%
  mutate(order = paste("o", order, sep="__")) %>%
  mutate(class = paste("c", class, sep="__")) %>%
  mutate(phylum = paste("p", phylum, sep="__")) %>%
  mutate(superkingdom = paste("k", superkingdom, sep="__"))

blastn.common <- blastn %>%
  group_by(sample, qseqid) %>%
  do(common_taxa = find_common_ancestor(.[taxa_headers])) %>% 
  ungroup() %>%
  unnest(common_taxa) #<---- nice 

#saveRDS(blastn.common, file="blastn_20181125_taxa_common.rds")
saveRDS(blastn.common, file="blastn_20181219_taxa_common.rds")
```

## Step 4: five percent quantile

The 5 percent quantile of blastn$pdient is 86.75%. So we set our threshold to 85%.

I used this one for filtering in **part 2**.

- 20181129_blastn_filtered.rds

```{r 20181129 pident needs a hard cutoff, eval=FALSE}
blastn <- readRDS("blastn_20181125_taxa.rds")

blastn %<>% filter(! is.na(taxaID))

## same bit score, different accession number but same species
blastn %<>%
  group_by(sample, qseqid, species) %>%
  filter(row_number() == 1) %>%
  ungroup()


### yue: only 5% of the 
q5 <- quantile(blastn$pident,0.05)
blastn %>%
  ggplot(aes( x = pident)) +
  geom_histogram() + 
  theme_bw() +
  geom_vline(xintercept = q5) +
  ggsave("20181129_hist_pident_blastn.pdf", width = 8, height = 5)

q5.2 <- quantile(blastn$qcov,0.05)
print(q5.2)

blastn %>%
  ggplot(aes( x = qcov)) +
  geom_histogram() + 
  theme_bw() +
  geom_vline(xintercept = q5.2) +
  ggsave("20181129_hist_qcov_blastn.pdf", width = 8, height = 5)

blastn %<>% filter(pident >= 85)

blastn %>% filter(qcov < 0.85) %>% filter(length < 10000) %>% ggplot(aes( x = length)) + geom_histogram()

blastn %<>% 
  filter((length <= 10000 & qcov >= 0.85) | length > 10000) 

saveRDS(blastn, file="20181129_blastn_filtered.rds")
```

## Step 5: merge 

- blastn_20181219_taxa_common_merge.rds

```{r, eval=FALSE}
blastn.common1 <- readRDS("20181219_RDS_data/blastn_20181125_taxa_common.rds")
blastn.common2 <- readRDS("20181219_RDS_data/blastn_20181219_taxa_common.rds")

blastn.common <- rbind(blastn.common1, blastn.common2)
saveRDS(blastn.common, file="blastn_20181219_taxa_common_merge.rds")
```

# perbase coverage

- contigs.per.base.df_20181120.rds

```{r per base coverage for contigs, eval=FALSE}
get_per_base_cov_contig <- function(filename){
  print(filename)
  per.base.cov <- read_delim(filename, delim="\t", col_names = F)
  colnames(per.base.cov) <- c("qseqid", "base", "cov")
  
  per.base.cov %>%
    group_by(qseqid) %>%
    summarise(perbaseSum= sum(cov), perbaseMedian = median(cov), perbaseSd = sd(cov), perbaseLen = n(), perbaseMin = min(cov), perbaseMax = max(cov), perbaseMean = mean(cov)) %>%
    ungroup()
}

depth_fp <- "sunbeam_output_20180731/sbx_contigs/reports"
suffix_pattern <- ".depth"

per.base.df <- data_frame(FileName = list.files(depth_fp, pattern=suffix_pattern)) %>%
  mutate(SampleID = sub(suffix_pattern, "", FileName)) %>%
  group_by(FileName) %>%
  do(get_per_base_cov_contig(file.path(depth_fp, .$FileName))) %>%
  ungroup()
  
saveRDS(per.base.df, file="contigs.per.base.df_20181120.rds")
```
